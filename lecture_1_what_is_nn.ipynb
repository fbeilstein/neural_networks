{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/Qufk5Ig2fMuy/HXpHxUK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fbeilstein/neural_networks/blob/master/lecture_1_what_is_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title How ML works\n",
        "%%html\n",
        "<link rel=\"stylesheet\" href=\"https://fbeilstein.github.io/machine_learning/js_common/styles.css\"/>\n",
        "<script src=\"https://fbeilstein.github.io/machine_learning/js_common/script.js\"></script>\n",
        "<style>\n",
        "  .container {\n",
        "    height: 500px;\n",
        "    display: flex;\n",
        "    flex-direction: column;\n",
        "    align-items: center;\n",
        "    justify-content: center;\n",
        "}\n",
        "\n",
        ".caption {\n",
        "    margin-bottom: 50px; /* Adds space between caption and list */\n",
        "}\n",
        "\n",
        ".centered-list {\n",
        "    display: flex;\n",
        "    flex-direction: column;\n",
        "    align-items: left;\n",
        "    justify-content: space-around;\n",
        "    gap: 40px; /* Increases space between list items */\n",
        "    //list-style-type: none;\n",
        "    padding: 0;\n",
        "    margin: 0;\n",
        "    font-size:35px;\n",
        "}\n",
        ".centered-list li {\n",
        "  position: relative;\n",
        "  padding-bottom: 20px; /* Ensures space for explanations */\n",
        "}\n",
        ".explanation {\n",
        "  font-size: 0.4em;\n",
        "  color: grey;\n",
        "  margin-top: 5px;\n",
        "  position: absolute; /* Makes the explanation float over the list item */\n",
        "  //left: 50%;\n",
        "  //transform: translateX(-50%);\n",
        "  top: 100%; /* Places the explanation just below each list item */\n",
        "  white-space: nowrap;\n",
        "  display: none; /* Initially hidden */\n",
        "}\n",
        ".explanationV {\n",
        "  font-size: 0.4em;\n",
        "  color: grey;\n",
        "  margin-top: 5px;\n",
        "  position: absolute; /* Makes the explanation float over the list item */\n",
        "  //left: 50%;\n",
        "  //transform: translateX(-50%);\n",
        "  top: 100%; /* Places the explanation just below each list item */\n",
        "  white-space: nowrap;\n",
        "  display: block; /* Initially hidden */\n",
        "}\n",
        "</style>\n",
        "<script>\n",
        "load_slides_from(\n",
        "[\n",
        "`<div style=\"height:500px; display:flex; align-items: center;\">\n",
        "  <img src='https://raw.githubusercontent.com/fbeilstein/presentations/refs/heads/master/presentation_for_December_3_2024/two_views.svg'></img>\n",
        "</div>\n",
        "`,\n",
        "`<div style=\"height:500px; display:flex; align-items: center;\">\n",
        "  <img src='https://raw.githubusercontent.com/fbeilstein/presentations/refs/heads/master/images/ML_as_function_search.svg'></img>\n",
        "</div>\n",
        "`,\n",
        "`<div style=\"height:500px; display:flex; align-items: center;\">\n",
        "  <img src='https://raw.githubusercontent.com/fbeilstein/presentations/refs/heads/master/images/image_to_Rn.svg'></img>\n",
        "</div>\n",
        "`,\n",
        "`<div style=\"height:500px; display:flex; align-items: center;\">\n",
        "  <img src='https://raw.githubusercontent.com/fbeilstein/presentations/refs/heads/master/images/hand_to_Rn.svg'></img>\n",
        "</div>\n",
        "`,\n",
        "`<div style=\"height:500px; display:flex; align-items: center;\">\n",
        "  <img src='https://raw.githubusercontent.com/fbeilstein/presentations/refs/heads/master/presentation_for_December_3_2024/ITP_hand_recognition.png' height=\"500px\"></img>\n",
        "</div>\n",
        "`,\n",
        "`\n",
        "<div style=\"height:500px; display:flex; align-items: center;\">\n",
        "  <img src='https://raw.githubusercontent.com/fbeilstein/presentations/refs/heads/master/images/face_to_Rn.svg'></img>\n",
        "</div>\n",
        "`,\n",
        "`<div style=\"height:500px; display:flex; align-items: center;\">\n",
        "  <img src='https://raw.githubusercontent.com/fbeilstein/presentations/refs/heads/master/presentation_for_December_3_2024/ITP_face_recognition.png' height=\"500px\"></img>\n",
        "</div>\n",
        "`,\n",
        "`\n",
        "<div style=\"height:500px;\">\n",
        "  <h2 class=\"caption\">We will get different ML methods depending on how we answer the following questions:</h2>\n",
        "  <ul class=\"centered-list\">\n",
        "    <li>\n",
        "      How do we choose the family of functions?\n",
        "      <p class=\"explanation\">The family of functions should be parametrized with a finite set of real numbers</p>\n",
        "    </li>\n",
        "    <li>\n",
        "      How do we measure the \"goodness\" of a function?\n",
        "      <p class=\"explanation\">We have no access to the \"perfect function\" so we should avoid using it</p>\n",
        "    </li>\n",
        "    <li>\n",
        "      How to maximize the goodness?\n",
        "      <p class=\"explanation\">We should build some iterative process that converges</p>\n",
        "    </li>\n",
        "  </ul>\n",
        "</div>\n",
        "`,\n",
        "`\n",
        "<div style=\"height:500px;\">\n",
        "  <h2 class=\"caption\">We will get different ML methods depending on how we answer the following questions:</h2>\n",
        "  <ul class=\"centered-list\">\n",
        "    <li>\n",
        "      How do we choose the family of functions?\n",
        "      <p class=\"explanationV\">The family of functions should be parametrized with a finite set of real numbers</p>\n",
        "    </li>\n",
        "    <li>\n",
        "      How do we measure the \"goodness\" of a function?\n",
        "      <p class=\"explanation\">We have no access to the \"perfect function\" so we should avoid using it</p>\n",
        "    </li>\n",
        "    <li>\n",
        "      How to maximize the goodness?\n",
        "      <p class=\"explanation\">We should build some iterative process that converges</p>\n",
        "    </li>\n",
        "  </ul>\n",
        "</div>\n",
        "`,\n",
        "`\n",
        "<div style=\"height:500px;\">\n",
        "  <h2 class=\"caption\">We will get different ML methods depending on how we answer the following questions:</h2>\n",
        "  <ul class=\"centered-list\">\n",
        "    <li>\n",
        "      How do we choose the family of functions?\n",
        "      <p class=\"explanationV\">The family of functions should be parametrized with a finite set of real numbers</p>\n",
        "    </li>\n",
        "    <li>\n",
        "      How do we measure the \"goodness\" of a function?\n",
        "      <p class=\"explanationV\">We have no access to the \"perfect function\" so we should avoid using it</p>\n",
        "    </li>\n",
        "    <li>\n",
        "      How to maximize the goodness?\n",
        "      <p class=\"explanation\">We should build some iterative process that converges</p>\n",
        "    </li>\n",
        "  </ul>\n",
        "</div>\n",
        "`,\n",
        "`\n",
        "<div style=\"height:500px;\">\n",
        "  <h2 class=\"caption\">We will get different ML methods depending on how we answer the following questions:</h2>\n",
        "  <ul class=\"centered-list\">\n",
        "    <li>\n",
        "      How do we choose the family of functions?\n",
        "      <p class=\"explanationV\">The family of functions should be parametrized with a finite set of real numbers</p>\n",
        "    </li>\n",
        "    <li>\n",
        "      How do we measure the \"goodness\" of a function?\n",
        "      <p class=\"explanationV\">We have no access to the \"perfect function\" so we should avoid using it</p>\n",
        "    </li>\n",
        "    <li>\n",
        "      How to maximize the goodness?\n",
        "      <p class=\"explanationV\">We should build some iterative process that converges</p>\n",
        "    </li>\n",
        "  </ul>\n",
        "</div>\n",
        "`\n",
        "])\n",
        "</script>"
      ],
      "metadata": {
        "cellView": "form",
        "id": "aEED5sYTm-8v",
        "outputId": "17857a7a-0a22-404d-c639-debe170e2565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<link rel=\"stylesheet\" href=\"https://fbeilstein.github.io/machine_learning/js_common/styles.css\"/>\n",
              "<script src=\"https://fbeilstein.github.io/machine_learning/js_common/script.js\"></script>\n",
              "<style>\n",
              "  .container {\n",
              "    height: 500px;\n",
              "    display: flex;\n",
              "    flex-direction: column;\n",
              "    align-items: center;\n",
              "    justify-content: center;\n",
              "}\n",
              "\n",
              ".caption {\n",
              "    margin-bottom: 50px; /* Adds space between caption and list */\n",
              "}\n",
              "\n",
              ".centered-list {\n",
              "    display: flex;\n",
              "    flex-direction: column;\n",
              "    align-items: left;\n",
              "    justify-content: space-around;\n",
              "    gap: 40px; /* Increases space between list items */\n",
              "    //list-style-type: none;\n",
              "    padding: 0;\n",
              "    margin: 0;\n",
              "    font-size:35px;\n",
              "}\n",
              ".centered-list li {\n",
              "  position: relative;\n",
              "  padding-bottom: 20px; /* Ensures space for explanations */\n",
              "}\n",
              ".explanation {\n",
              "  font-size: 0.4em;\n",
              "  color: grey;\n",
              "  margin-top: 5px;\n",
              "  position: absolute; /* Makes the explanation float over the list item */\n",
              "  //left: 50%;\n",
              "  //transform: translateX(-50%);\n",
              "  top: 100%; /* Places the explanation just below each list item */\n",
              "  white-space: nowrap;\n",
              "  display: none; /* Initially hidden */\n",
              "}\n",
              ".explanationV {\n",
              "  font-size: 0.4em;\n",
              "  color: grey;\n",
              "  margin-top: 5px;\n",
              "  position: absolute; /* Makes the explanation float over the list item */\n",
              "  //left: 50%;\n",
              "  //transform: translateX(-50%);\n",
              "  top: 100%; /* Places the explanation just below each list item */\n",
              "  white-space: nowrap;\n",
              "  display: block; /* Initially hidden */\n",
              "}\n",
              "</style>\n",
              "<script>\n",
              "load_slides_from(\n",
              "[\n",
              "`<div style=\"height:500px; display:flex; align-items: center;\">\n",
              "  <img src='https://raw.githubusercontent.com/fbeilstein/presentations/refs/heads/master/presentation_for_December_3_2024/two_views.svg'></img>\n",
              "</div>\n",
              "`,\n",
              "`<div style=\"height:500px; display:flex; align-items: center;\">\n",
              "  <img src='https://raw.githubusercontent.com/fbeilstein/presentations/refs/heads/master/images/ML_as_function_search.svg'></img>\n",
              "</div>\n",
              "`,\n",
              "`<div style=\"height:500px; display:flex; align-items: center;\">\n",
              "  <img src='https://raw.githubusercontent.com/fbeilstein/presentations/refs/heads/master/images/image_to_Rn.svg'></img>\n",
              "</div>\n",
              "`,\n",
              "`<div style=\"height:500px; display:flex; align-items: center;\">\n",
              "  <img src='https://raw.githubusercontent.com/fbeilstein/presentations/refs/heads/master/images/hand_to_Rn.svg'></img>\n",
              "</div>\n",
              "`,\n",
              "`<div style=\"height:500px; display:flex; align-items: center;\">\n",
              "  <img src='https://raw.githubusercontent.com/fbeilstein/presentations/refs/heads/master/presentation_for_December_3_2024/ITP_hand_recognition.png' height=\"500px\"></img>\n",
              "</div>\n",
              "`,\n",
              "`\n",
              "<div style=\"height:500px; display:flex; align-items: center;\">\n",
              "  <img src='https://raw.githubusercontent.com/fbeilstein/presentations/refs/heads/master/images/face_to_Rn.svg'></img>\n",
              "</div>\n",
              "`,\n",
              "`<div style=\"height:500px; display:flex; align-items: center;\">\n",
              "  <img src='https://raw.githubusercontent.com/fbeilstein/presentations/refs/heads/master/presentation_for_December_3_2024/ITP_face_recognition.png' height=\"500px\"></img>\n",
              "</div>\n",
              "`,\n",
              "`\n",
              "<div style=\"height:500px;\">\n",
              "  <h2 class=\"caption\">We will get different ML methods depending on how we answer the following questions:</h2>\n",
              "  <ul class=\"centered-list\">\n",
              "    <li>\n",
              "      How do we choose the family of functions?\n",
              "      <p class=\"explanation\">The family of functions should be parametrized with a finite set of real numbers</p>\n",
              "    </li>\n",
              "    <li>\n",
              "      How do we measure the \"goodness\" of a function?\n",
              "      <p class=\"explanation\">We have no access to the \"perfect function\" so we should avoid using it</p>\n",
              "    </li>\n",
              "    <li>\n",
              "      How to maximize the goodness?\n",
              "      <p class=\"explanation\">We should build some iterative process that converges</p>\n",
              "    </li>\n",
              "  </ul>\n",
              "</div>\n",
              "`,\n",
              "`\n",
              "<div style=\"height:500px;\">\n",
              "  <h2 class=\"caption\">We will get different ML methods depending on how we answer the following questions:</h2>\n",
              "  <ul class=\"centered-list\">\n",
              "    <li>\n",
              "      How do we choose the family of functions?\n",
              "      <p class=\"explanationV\">The family of functions should be parametrized with a finite set of real numbers</p>\n",
              "    </li>\n",
              "    <li>\n",
              "      How do we measure the \"goodness\" of a function?\n",
              "      <p class=\"explanation\">We have no access to the \"perfect function\" so we should avoid using it</p>\n",
              "    </li>\n",
              "    <li>\n",
              "      How to maximize the goodness?\n",
              "      <p class=\"explanation\">We should build some iterative process that converges</p>\n",
              "    </li>\n",
              "  </ul>\n",
              "</div>\n",
              "`,\n",
              "`\n",
              "<div style=\"height:500px;\">\n",
              "  <h2 class=\"caption\">We will get different ML methods depending on how we answer the following questions:</h2>\n",
              "  <ul class=\"centered-list\">\n",
              "    <li>\n",
              "      How do we choose the family of functions?\n",
              "      <p class=\"explanationV\">The family of functions should be parametrized with a finite set of real numbers</p>\n",
              "    </li>\n",
              "    <li>\n",
              "      How do we measure the \"goodness\" of a function?\n",
              "      <p class=\"explanationV\">We have no access to the \"perfect function\" so we should avoid using it</p>\n",
              "    </li>\n",
              "    <li>\n",
              "      How to maximize the goodness?\n",
              "      <p class=\"explanation\">We should build some iterative process that converges</p>\n",
              "    </li>\n",
              "  </ul>\n",
              "</div>\n",
              "`,\n",
              "`\n",
              "<div style=\"height:500px;\">\n",
              "  <h2 class=\"caption\">We will get different ML methods depending on how we answer the following questions:</h2>\n",
              "  <ul class=\"centered-list\">\n",
              "    <li>\n",
              "      How do we choose the family of functions?\n",
              "      <p class=\"explanationV\">The family of functions should be parametrized with a finite set of real numbers</p>\n",
              "    </li>\n",
              "    <li>\n",
              "      How do we measure the \"goodness\" of a function?\n",
              "      <p class=\"explanationV\">We have no access to the \"perfect function\" so we should avoid using it</p>\n",
              "    </li>\n",
              "    <li>\n",
              "      How to maximize the goodness?\n",
              "      <p class=\"explanationV\">We should build some iterative process that converges</p>\n",
              "    </li>\n",
              "  </ul>\n",
              "</div>\n",
              "`\n",
              "])\n",
              "</script>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##How do we define the family of functions\n",
        "%%html\n",
        "<link rel=\"stylesheet\" href=\"https://fbeilstein.github.io/machine_learning/js_common/styles.css\"/>\n",
        "<script src=\"https://fbeilstein.github.io/machine_learning/js_common/script.js\"></script>\n",
        "<script>\n",
        "load_slides_from(\n",
        "[`\n",
        "<img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/images/two_neurons.jpg\" width=750>\n",
        "`,`\n",
        "<img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/images/activation_functions.jpg\" width=750>\n",
        "`,`\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Colored_neural_network.svg/399px-Colored_neural_network.svg.png\">\n",
        "`,`\n",
        "<h4>Fully connected layer</h4>\n",
        "<img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/images/nn_layers/fully_connected_layer.svg\" height=550>\n",
        "`,`\n",
        "<h4>Convolutional layer</h4>\n",
        "<img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/images/nn_layers/convolutional_layer.png\" height=550>\n",
        "`,`\n",
        "<h4>Receptive Field</h4>\n",
        "<img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/presentation_for_December_3_2024/receptive_field.png\" height=550>\n",
        "`,`\n",
        "<h4>Cornsweet Illusion</h4>\n",
        "<img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/presentation_for_December_3_2024/cornsweet_illusion.png\" height=550>\n",
        "`,`\n",
        "<h4>MaxPooling layer</h4>\n",
        "<img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/images/nn_layers/maxpooling_layer.png\" width=750>\n",
        "`,`\n",
        "<h4>RNN layer</h4>\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Recurrent_neural_network_unfold.svg/960px-Recurrent_neural_network_unfold.svg.png\" width=750>\n",
        "`,`\n",
        "<h4>Batch Normalization layer</h4>\n",
        "<img src=\"https://raw.githubusercontent.com/fbeilstein/neural_networks/master/lecture_1_what_is_nn/BN_train.png\" width=550>\n",
        "<img src=\"https://raw.githubusercontent.com/fbeilstein/neural_networks/master/lecture_1_what_is_nn/BN_inference.png\" width=550>\n",
        "`,`\n",
        "<h4>Dropout layer</h4>\n",
        "<img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/images/nn_layers/dropout_layer.webp\" width=750>\n",
        "`,\n",
        "\n",
        "`\n",
        "<h3>LeNet</h3>\n",
        "<b>Parameters:</b> ~60,000\n",
        "<b>Known for:</b> Early CNN for digit classification.\n",
        "<b>Use cases:</b> Image classification, especially handwritten digits.\n",
        "<b>Structure:</b> Simple convolutional layers with subsampling and fully-connected layers.\n",
        "<img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/images/nn_architectures/lenet_architecture.png\" height=550>\n",
        "`,`\n",
        "<table border=\"1\">\n",
        "    <thead>\n",
        "        <tr>\n",
        "            <th>Neural Network</th>\n",
        "            <th>Parameters</th>\n",
        "            <th>Known For</th>\n",
        "            <th>Use Cases</th>\n",
        "            <th>Structure</th>\n",
        "            <th>Image</th>\n",
        "        </tr>\n",
        "    </thead>\n",
        "    <tbody>\n",
        "        <tr>\n",
        "            <td>LeNet</td>\n",
        "            <td>~60,000</td>\n",
        "            <td>Early CNN for digit classification</td>\n",
        "            <td>Image classification, especially handwritten digits</td>\n",
        "            <td>Simple convolutional layers with subsampling and fully connected layers</td>\n",
        "            <td><img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/images/nn_architectures/lenet_architecture.png\" height=\"50\"></td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>AlexNet</td>\n",
        "            <td>~60 million</td>\n",
        "            <td>Winning 2012 ImageNet competition, popularizing deep learning</td>\n",
        "            <td>Object detection, image classification</td>\n",
        "            <td>Deep CNN with ReLU activations, dropout for regularization, and overlapping max-pooling</td>\n",
        "            <td><img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/images/nn_architectures/alexnet_architecture.png\" height=\"50\"></td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>ResNet-18</td>\n",
        "            <td>~11.7 million</td>\n",
        "            <td>Introducing residual blocks, enabling very deep networks</td>\n",
        "            <td>Image classification, transfer learning</td>\n",
        "            <td>Stack of residual blocks with skip connections to solve vanishing gradients</td>\n",
        "            <td><img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/images/nn_architectures/Resnet18_architecture.svg\" width=\"50\"></td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>U-Net</td>\n",
        "            <td>Varies; typically a few million</td>\n",
        "            <td>Biomedical image segmentation</td>\n",
        "            <td>Segmentation tasks</td>\n",
        "            <td>Encoder-decoder network with skip connections between corresponding levels for precise localization</td>\n",
        "            <td><img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/images/nn_architectures/unet_architecture.png\" height=\"50\"></td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>VGG-16</td>\n",
        "            <td>~138 million</td>\n",
        "            <td>Depth and simplicity, with 3x3 convolutions</td>\n",
        "            <td>General-purpose feature extraction, image classification</td>\n",
        "            <td>Deep network of consecutive 3x3 convolutions, max-pooling, and fully connected layers</td>\n",
        "            <td><img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/images/nn_architectures/vgg16_architecture.png\" height=\"50\"></td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>FCN-32</td>\n",
        "            <td>Based on a pretrained network (e.g., VGG)</td>\n",
        "            <td>Pixel-wise prediction, pioneering semantic segmentation</td>\n",
        "            <td>Semantic segmentation</td>\n",
        "            <td>Fully convolutional; uses deconvolution layers to upsample and predict per-pixel class labels</td>\n",
        "            <td><img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/images/nn_architectures/fcn32_architecture.png\" height=\"50\"></td>\n",
        "        </tr>\n",
        "    </tbody>\n",
        "</table>\n",
        "`])"
      ],
      "metadata": {
        "cellView": "form",
        "outputId": "a700942f-6587-416a-f336-5740ab70b5dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "mMhOQdN6Z3Vz"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<link rel=\"stylesheet\" href=\"https://fbeilstein.github.io/machine_learning/js_common/styles.css\"/>\n",
              "<script src=\"https://fbeilstein.github.io/machine_learning/js_common/script.js\"></script>\n",
              "<script>\n",
              "load_slides_from(\n",
              "[`\n",
              "<img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/images/two_neurons.jpg\" width=750>\n",
              "`,`\n",
              "<img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/images/activation_functions.jpg\" width=750>\n",
              "`,`\n",
              "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Colored_neural_network.svg/399px-Colored_neural_network.svg.png\">\n",
              "`,`\n",
              "<h4>Fully connected layer</h4>\n",
              "<img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/images/nn_layers/fully_connected_layer.svg\" height=550>\n",
              "`,`\n",
              "<h4>Convolutional layer</h4>\n",
              "<img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/images/nn_layers/convolutional_layer.png\" height=550>\n",
              "`,`\n",
              "<h4>Receptive Field</h4>\n",
              "<img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/presentation_for_December_3_2024/receptive_field.png\" height=550>\n",
              "`,`\n",
              "<h4>Cornsweet Illusion</h4>\n",
              "<img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/presentation_for_December_3_2024/cornsweet_illusion.png\" height=550>\n",
              "`,`\n",
              "<h4>MaxPooling layer</h4>\n",
              "<img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/images/nn_layers/maxpooling_layer.png\" width=750>\n",
              "`,`\n",
              "<h4>RNN layer</h4>\n",
              "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Recurrent_neural_network_unfold.svg/960px-Recurrent_neural_network_unfold.svg.png\" width=750>\n",
              "`,`\n",
              "<h4>Batch Normalization layer</h4>\n",
              "<img src=\"https://raw.githubusercontent.com/fbeilstein/neural_networks/master/lecture_1_what_is_nn/BN_train.png\" width=550>\n",
              "<img src=\"https://raw.githubusercontent.com/fbeilstein/neural_networks/master/lecture_1_what_is_nn/BN_inference.png\" width=550>\n",
              "`,`\n",
              "<h4>Dropout layer</h4>\n",
              "<img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/images/nn_layers/dropout_layer.webp\" width=750>\n",
              "`,\n",
              "\n",
              "`\n",
              "<h3>LeNet</h3>\n",
              "<b>Parameters:</b> ~60,000\n",
              "<b>Known for:</b> Early CNN for digit classification.\n",
              "<b>Use cases:</b> Image classification, especially handwritten digits.\n",
              "<b>Structure:</b> Simple convolutional layers with subsampling and fully-connected layers.\n",
              "<img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/images/nn_architectures/lenet_architecture.png\" height=550>\n",
              "`,`\n",
              "<table border=\"1\">\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>Neural Network</th>\n",
              "            <th>Parameters</th>\n",
              "            <th>Known For</th>\n",
              "            <th>Use Cases</th>\n",
              "            <th>Structure</th>\n",
              "            <th>Image</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>LeNet</td>\n",
              "            <td>~60,000</td>\n",
              "            <td>Early CNN for digit classification</td>\n",
              "            <td>Image classification, especially handwritten digits</td>\n",
              "            <td>Simple convolutional layers with subsampling and fully connected layers</td>\n",
              "            <td><img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/images/nn_architectures/lenet_architecture.png\" height=\"50\"></td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>AlexNet</td>\n",
              "            <td>~60 million</td>\n",
              "            <td>Winning 2012 ImageNet competition, popularizing deep learning</td>\n",
              "            <td>Object detection, image classification</td>\n",
              "            <td>Deep CNN with ReLU activations, dropout for regularization, and overlapping max-pooling</td>\n",
              "            <td><img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/images/nn_architectures/alexnet_architecture.png\" height=\"50\"></td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>ResNet-18</td>\n",
              "            <td>~11.7 million</td>\n",
              "            <td>Introducing residual blocks, enabling very deep networks</td>\n",
              "            <td>Image classification, transfer learning</td>\n",
              "            <td>Stack of residual blocks with skip connections to solve vanishing gradients</td>\n",
              "            <td><img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/images/nn_architectures/Resnet18_architecture.svg\" width=\"50\"></td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>U-Net</td>\n",
              "            <td>Varies; typically a few million</td>\n",
              "            <td>Biomedical image segmentation</td>\n",
              "            <td>Segmentation tasks</td>\n",
              "            <td>Encoder-decoder network with skip connections between corresponding levels for precise localization</td>\n",
              "            <td><img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/images/nn_architectures/unet_architecture.png\" height=\"50\"></td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>VGG-16</td>\n",
              "            <td>~138 million</td>\n",
              "            <td>Depth and simplicity, with 3x3 convolutions</td>\n",
              "            <td>General-purpose feature extraction, image classification</td>\n",
              "            <td>Deep network of consecutive 3x3 convolutions, max-pooling, and fully connected layers</td>\n",
              "            <td><img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/images/nn_architectures/vgg16_architecture.png\" height=\"50\"></td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>FCN-32</td>\n",
              "            <td>Based on a pretrained network (e.g., VGG)</td>\n",
              "            <td>Pixel-wise prediction, pioneering semantic segmentation</td>\n",
              "            <td>Semantic segmentation</td>\n",
              "            <td>Fully convolutional; uses deconvolution layers to upsample and predict per-pixel class labels</td>\n",
              "            <td><img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/images/nn_architectures/fcn32_architecture.png\" height=\"50\"></td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>\n",
              "`])\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Category                     | `torch.nn` Modules                                       | Use Case & Sketch Description                                                                                                           |\n",
        "| ---------------------------- | -------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| **Linear (Fully Connected)** | `nn.Linear(in_features, out_features)`                   | Classic dense layer; connects all inputs to all outputs. Ideal for tabular or flattened features. |\n",
        "| **Convolutional (CNN)**      | `nn.Conv2d(in_ch, out_ch, kernel_size, stride, padding)` | Extracts local patterns in images — think sliding window filters.                                                                       |\n",
        "| **Pooling**                  | `nn.MaxPool2d`, `nn.AvgPool2d`                           | Reduces spatial dimensions, downsampling features. Common after convolutions.                                                           |\n",
        "| **Recurrent/Sequential**     | `nn.RNN`, `nn.LSTM`, `nn.GRU`                            | For sequences/text/audio — maintains hidden state across time steps.                                                                    |\n",
        "| **Normalization**            | `nn.BatchNorm1d/2d`, `nn.LayerNorm`                      | Standardizes activations; improves convergence.                                                                                         |\n",
        "| **Dropout**                  | `nn.Dropout(p)`                                          | Stochastically zeroes units during training; combats overfitting.                                                                       |\n",
        "| **Activation Functions**     | `nn.ReLU`, `nn.Sigmoid`, `nn.Tanh`                       | Applies non-linear transformation element-wise.                                                                                         |\n",
        "| **Flatten / Reshape**        | `nn.Flatten()`, `tensor.view(...)`                       | Restructures tensor — e.g. from convolutional to linear layers.                                                                         |\n",
        "| **Sequential Container**     | `nn.Sequential(...)`                                     | Chains layers in a defined order (e.g. `Flatten → Linear → ReLU`).                                                                      |\n",
        "| **Transformer**              | `nn.Transformer`, `nn.TransformerEncoderLayer`, etc.     | For attention-based sequence modeling.                                                                                                  |"
      ],
      "metadata": {
        "id": "ClmD7lPdLXQN"
      }
    }
  ]
}