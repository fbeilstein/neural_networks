{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPk5mKOlt//ltRDcWaE7apb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fbeilstein/neural_networks/blob/master/lecture_3_nn_architectures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LeNet"
      ],
      "metadata": {
        "id": "i_HrzQNxooZP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Developed by Yann LeCun et al. in 1998.\n",
        "\n",
        "* One of the first successful CNNs, applied to handwritten digit recognition (MNIST).\n",
        "\n",
        "* Paved the way for modern deep learning in computer vision.\n",
        "\n",
        "-----\n",
        "\n",
        "* Uses tanh activation (ReLU was not yet popular).\n",
        "* Uses average pooling, not max pooling (which became popular later).\n",
        "* No Dropout or BatchNorm. These techniques didn't exist at the time. LeNet-5 is much shallower and simpler.\n",
        "\n",
        "-----\n",
        "\n",
        "* CNN structure idea: alternating convolution + pooling.\n",
        "\n",
        "* Weight sharing: dramatically reduces number of parameters vs fully connected layers.\n",
        "\n",
        "* Local receptive fields: how neurons look only at parts of the image.\n",
        "\n",
        "* Low parameter count: around 60k parameters—tiny by modern standards!\n",
        "\n",
        "* Bias-variance balance: good example of a simple model that avoids overfitting by design."
      ],
      "metadata": {
        "id": "x_fQrQGV14ni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title architecture\n",
        "%%html\n",
        "<img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/images/nn_architectures/lenet_architecture.png\" width='550'>"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cl6yMfpUzXD3",
        "outputId": "19465b40-ad6c-4ccb-8731-8e97404e44c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/images/nn_architectures/lenet_architecture.png\" width='550'>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 1. LeNet-5 architecture\n",
        "class LeNet5(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LeNet5, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 6, kernel_size=5)   # 28x28 -> 24x24\n",
        "    self.pool1 = nn.AvgPool2d(kernel_size=2)      # 24x24 -> 12x12\n",
        "    self.conv2 = nn.Conv2d(6, 16, kernel_size=5)  # 12x12 -> 8x8\n",
        "    self.pool2 = nn.AvgPool2d(kernel_size=2)      # 8x8 -> 4x4\n",
        "    self.conv3 = nn.Conv2d(16, 120, kernel_size=4)  # 4x4 -> 1x1\n",
        "\n",
        "    self.fc1 = nn.Linear(120, 84)\n",
        "    self.fc2 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = torch.tanh(self.conv1(x))\n",
        "    x = self.pool1(x)\n",
        "    x = torch.tanh(self.conv2(x))\n",
        "    x = self.pool2(x)\n",
        "    x = torch.tanh(self.conv3(x))\n",
        "    x = x.view(-1, 120)\n",
        "    x = torch.tanh(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "FJJxggZv0xDs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Prepare data\n",
        "transform = transforms.Compose([\n",
        "  transforms.Resize((28, 28)),  # Just to be sure\n",
        "  transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_data = datasets.MNIST(root='data', train=True, transform=transform, download=True)\n",
        "test_data  = datasets.MNIST(root='data', train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader  = DataLoader(test_data, batch_size=1000, shuffle=False)\n",
        "\n",
        "# 3. Training setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = LeNet5().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 4. Training loop\n",
        "for epoch in range(5):\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "  for images, labels in train_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "  print(f\"Epoch {epoch+1}, Loss: {total_loss:.2f}\")\n"
      ],
      "metadata": {
        "id": "iYhw02v002zH",
        "outputId": "3fa31e15-76f9-4fd3-9392-52e842c3cc72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 55.0MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.72MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.5MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.08MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 294.13\n",
            "Epoch 2, Loss: 96.04\n",
            "Epoch 3, Loss: 66.10\n",
            "Epoch 4, Loss: 50.09\n",
            "Epoch 5, Loss: 40.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for images, labels in test_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "id": "YqnQxJBj1ACR",
        "outputId": "ba695f39-7969-4cf7-b991-8bbd60765e17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 98.45%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#AlexNet"
      ],
      "metadata": {
        "id": "Zd5IVXfRsHV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Breakthrough: AlexNet won the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2012 by a huge margin.\n",
        "\n",
        "* Popularized CNNs: It showed that convolutional neural networks trained on GPUs could achieve state-of-the-art results on real-world large-scale datasets.\n",
        "\n",
        "* Catalyst for Deep Learning: It essentially started the current deep learning boom in computer vision.\n",
        "\n",
        "--------\n",
        "\n",
        "**New Features/Ideas**\n",
        "\n",
        "* Deep Architecture\n",
        "* ReLU Activation\tinstead of tanh/sigmoid for faster convergence\n",
        "* Introduced dropout to prevent overfitting in fully connected layers\n",
        "* Used overlapping $3\\times 3$ pooling (stride 2) instead of $2 \\times 2$ non-overlapping\n",
        "* Used data augmentation techniques like image translation and reflection to expand dataset\n",
        "* Trained on 2 GPUs, splitting the model across them (early model parallelism)\n",
        "* Used Local Response Normalization (LRN) to encourage lateral inhibition (now less common)"
      ],
      "metadata": {
        "id": "y3PUAjNh3fXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title architecture\n",
        "%%html\n",
        "<img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/images/nn_architectures/alexnet_architecture.png\" width='550'>"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vG4_RP4920g1",
        "outputId": "f9eea36f-01e3-4510-8b57-1aafd0a75cea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/fbeilstein/presentations/master/images/nn_architectures/alexnet_architecture.png\" width='550'>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define AlexNet for CIFAR-10 (input 3x32x32 instead of 224x224)\n",
        "class AlexNet(nn.Module):\n",
        "  def __init__(self, num_classes=10):\n",
        "    super(AlexNet, self).__init__()\n",
        "    self.features = nn.Sequential(\n",
        "      nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),  # CIFAR-10: input 32x32, here causes strong shrink\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "      nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "      nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "      nn.Dropout(),\n",
        "      nn.LazyLinear(4096),  # CIFAR input is small; we end up with tiny feature maps\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Dropout(),\n",
        "      nn.Linear(4096, 4096),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Linear(4096, num_classes),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.features(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.classifier(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "spEJzPB85bJx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforms\n",
        "#transform = transforms.Compose([\n",
        "#  transforms.Resize(32),  # Resize if needed\n",
        "#  transforms.ToTensor(),\n",
        "#  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "#])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "  transforms.Resize(224),  # This fixes the problem\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize((0.5,), (0.5,)),\n",
        "])\n",
        "\n",
        "# Download CIFAR-10\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=100, shuffle=False)\n"
      ],
      "metadata": {
        "id": "xLOUxcZf55fZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = AlexNet(num_classes=10).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(5):  # keep small on Colab\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  for images, labels in trainloader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "\n",
        "  print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader):.4f}\")"
      ],
      "metadata": {
        "id": "DzUUSMH06CjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for images, labels in testloader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "id": "Ys9lnpY56N2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Autoencoder"
      ],
      "metadata": {
        "id": "9aq4ZrT5og2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Manual PCA\n",
        "%%html\n",
        "<iframe title=\"Demo\"\n",
        "        src=\"https://fbeilstein.github.io/machine_learning/lecture_12_principal_component_analysis/demo_pca.html\"\n",
        "        width=\"800\" height=\"450\"\n",
        "        marginwidth=\"0\" marginheight=\"0\" frameborder=\"0\"\n",
        "        scrolling=\"no\">\n",
        "Your browser does not support IFrames.\n",
        "</iframe>\n"
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "2WKD2y2Mz9tE",
        "outputId": "0302e8b2-79bf-4011-a644-7939520635d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<iframe title=\"Demo\" \n",
              "        src=\"https://fbeilstein.github.io/machine_learning/lecture_12_principal_component_analysis/demo_pca.html\" \n",
              "        width=\"800\" height=\"450\" \n",
              "        marginwidth=\"0\" marginheight=\"0\" frameborder=\"0\" \n",
              "        scrolling=\"no\">\n",
              "Your browser does not support IFrames.\n",
              "</iframe>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Variational Autoencoder (VAE)"
      ],
      "metadata": {
        "id": "ZECY8NJ8okwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #General Idea\n",
        "%%html\n",
        "<link rel=\"stylesheet\" href=\"https://fbeilstein.github.io/machine_learning/js_common/styles.css\"/>\n",
        "<script src=\"https://fbeilstein.github.io/machine_learning/js_common/script.js\"></script>\n",
        "<script>\n",
        "load_slides_from(\n",
        "[`\n",
        "<img src=\"https://raw.githubusercontent.com/fbeilstein/neural_networks/master/lecture_3_nn_architectures/VAE1.webp\" width=750>\n",
        "`,`\n",
        "<img src=\"https://raw.githubusercontent.com/fbeilstein/neural_networks/master/lecture_3_nn_architectures/VAE2.webp\" width=750>\n",
        "`,`\n",
        "<img src=\"https://raw.githubusercontent.com/fbeilstein/neural_networks/master/lecture_3_nn_architectures/VAE3.webp\" width=750>\n",
        "`,`\n",
        "<img src=\"https://raw.githubusercontent.com/fbeilstein/neural_networks/master/lecture_3_nn_architectures/VAE4.webp\" width=750>\n",
        "`,`\n",
        "<img src=\"https://raw.githubusercontent.com/fbeilstein/neural_networks/master/lecture_3_nn_architectures/VAE5.webp\" width=750>\n",
        "`,`\n",
        "<img src=\"https://raw.githubusercontent.com/fbeilstein/neural_networks/master/lecture_3_nn_architectures/VAE6.webp\" width=750>\n",
        "`])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "cellView": "form",
        "id": "KQoLidn6tLsf",
        "outputId": "fd0c5c0f-a307-4677-83e9-c9d401a3439e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<link rel=\"stylesheet\" href=\"https://fbeilstein.github.io/machine_learning/js_common/styles.css\"/>\n",
              "<script src=\"https://fbeilstein.github.io/machine_learning/js_common/script.js\"></script>\n",
              "<script>\n",
              "load_slides_from(\n",
              "[`\n",
              "<img src=\"https://raw.githubusercontent.com/fbeilstein/neural_networks/master/lecture_3_nn_architectures/VAE1.webp\" width=750>\n",
              "`,`\n",
              "<img src=\"https://raw.githubusercontent.com/fbeilstein/neural_networks/master/lecture_3_nn_architectures/VAE2.webp\" width=750>\n",
              "`,`\n",
              "<img src=\"https://raw.githubusercontent.com/fbeilstein/neural_networks/master/lecture_3_nn_architectures/VAE3.webp\" width=750>\n",
              "`,`\n",
              "<img src=\"https://raw.githubusercontent.com/fbeilstein/neural_networks/master/lecture_3_nn_architectures/VAE4.webp\" width=750>\n",
              "`,`\n",
              "<img src=\"https://raw.githubusercontent.com/fbeilstein/neural_networks/master/lecture_3_nn_architectures/VAE5.webp\" width=750>\n",
              "`,`\n",
              "<img src=\"https://raw.githubusercontent.com/fbeilstein/neural_networks/master/lecture_3_nn_architectures/VAE6.webp\" width=750>\n",
              "`])\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "train_data = datasets.MNIST(root=\"data\", train=True, transform=transform, download=True)\n",
        "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
        "\n",
        "class VAE(nn.Module):\n",
        "  def __init__(self, latent_dim=20):\n",
        "    super(VAE, self).__init__()\n",
        "    self.encoder = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(28*28, 400),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "    self.fc_mu = nn.Linear(400, latent_dim)\n",
        "    self.fc_logvar = nn.Linear(400, latent_dim)\n",
        "\n",
        "    self.decoder = nn.Sequential(\n",
        "        nn.Linear(latent_dim, 400),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(400, 28*28),\n",
        "        nn.Sigmoid()  # output in [0,1]\n",
        "    )\n",
        "\n",
        "  def reparameterize(self, mu, logvar):\n",
        "    std = torch.exp(0.5 * logvar)\n",
        "    eps = torch.randn_like(std)\n",
        "    return mu + eps * std  # reparameterization trick\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.encoder(x)\n",
        "    mu = self.fc_mu(x)\n",
        "    logvar = self.fc_logvar(x)\n",
        "    z = self.reparameterize(mu, logvar)\n",
        "    recon = self.decoder(z)\n",
        "    return recon.view(-1, 1, 28, 28), mu, logvar\n",
        "\n",
        "def loss_function(recon_x, x, mu, logvar):\n",
        "  recon_loss = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
        "  kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "  return recon_loss + kl_div\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = VAE(latent_dim=20).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "for epoch in range(1, 11):\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "  for x, _ in train_loader:\n",
        "    x = x.to(device)\n",
        "    recon_x, mu, logvar = model(x)\n",
        "    loss = loss_function(recon_x, x, mu, logvar)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "  print(f\"Epoch {epoch}, Loss: {total_loss/len(train_loader.dataset):.2f}\")\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  x, _ = next(iter(train_loader))\n",
        "  x = x.to(device)\n",
        "  recon_x, _, _ = model(x)\n",
        "\n",
        "  fig, axs = plt.subplots(2, 8, figsize=(12, 3))\n",
        "  for i in range(8):\n",
        "    axs[0, i].imshow(x[i].cpu().squeeze(), cmap=\"gray\")\n",
        "    axs[1, i].imshow(recon_x[i].cpu().squeeze(), cmap=\"gray\")\n",
        "    axs[0, i].axis(\"off\")\n",
        "    axs[1, i].axis(\"off\")\n",
        "  axs[0, 0].set_ylabel(\"Input\")\n",
        "  axs[1, 0].set_ylabel(\"Recon\")\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "fDhr-9WjxsqF",
        "outputId": "b23b8f56-d861-46a1-ab05-0811893ccdd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 18.2MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 486kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.50MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.90MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 163.97\n",
            "Epoch 2, Loss: 121.15\n",
            "Epoch 3, Loss: 114.52\n",
            "Epoch 4, Loss: 111.60\n",
            "Epoch 5, Loss: 109.86\n",
            "Epoch 6, Loss: 108.63\n",
            "Epoch 7, Loss: 107.83\n",
            "Epoch 8, Loss: 107.15\n",
            "Epoch 9, Loss: 106.65\n",
            "Epoch 10, Loss: 106.19\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x300 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ResNet"
      ],
      "metadata": {
        "id": "TvpQR6QLotTR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![img](https://raw.githubusercontent.com/fbeilstein/presentations/master/images/nn_architectures/Resnet18_architecture.svg)"
      ],
      "metadata": {
        "id": "5MViYQNMsRem"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#U-Net"
      ],
      "metadata": {
        "id": "KHRQfm35ou0W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![img](https://raw.githubusercontent.com/fbeilstein/presentations/master/images/nn_architectures/unet_architecture.png)"
      ],
      "metadata": {
        "id": "OgyHPvl3sYp3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#VGG-16"
      ],
      "metadata": {
        "id": "OvWx-6FvsgiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![img](https://raw.githubusercontent.com/fbeilstein/presentations/master/images/nn_architectures/vgg16_architecture.png)"
      ],
      "metadata": {
        "id": "nnJBKftasiA-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FCN-32"
      ],
      "metadata": {
        "id": "ZpsmOWL2sosp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![img](https://raw.githubusercontent.com/fbeilstein/presentations/master/images/nn_architectures/fcn32_architecture.png)"
      ],
      "metadata": {
        "id": "FaOmwEtgsqXj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GAN"
      ],
      "metadata": {
        "id": "Mqrj5O8oo0bE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #General Idea\n",
        "%%html\n",
        "<link rel=\"stylesheet\" href=\"https://fbeilstein.github.io/machine_learning/js_common/styles.css\"/>\n",
        "<script src=\"https://fbeilstein.github.io/machine_learning/js_common/script.js\"></script>\n",
        "<script>\n",
        "load_slides_from(\n",
        "[`\n",
        "<img src=\"https://raw.githubusercontent.com/fbeilstein/neural_networks/master/lecture_3_nn_architectures/GAN1.webp\" width=750>\n",
        "`,`\n",
        "<img src=\"https://raw.githubusercontent.com/fbeilstein/neural_networks/master/lecture_3_nn_architectures/GAN2.webp\" width=750>\n",
        "`,`\n",
        "<img src=\"https://raw.githubusercontent.com/fbeilstein/neural_networks/master/lecture_3_nn_architectures/GAN3.webp\" width=750>\n",
        "`])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "cellView": "form",
        "id": "BkWn78t8rKuW",
        "outputId": "565a2550-d80b-480a-b610-9e07c89d5ca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<link rel=\"stylesheet\" href=\"https://fbeilstein.github.io/machine_learning/js_common/styles.css\"/>\n",
              "<script src=\"https://fbeilstein.github.io/machine_learning/js_common/script.js\"></script>\n",
              "<script>\n",
              "load_slides_from(\n",
              "[`\n",
              "<img src=\"https://raw.githubusercontent.com/fbeilstein/neural_networks/master/lecture_3_nn_architectures/GAN1.webp\" width=750>\n",
              "`,`\n",
              "<img src=\"https://raw.githubusercontent.com/fbeilstein/neural_networks/master/lecture_3_nn_architectures/GAN2.webp\" width=750>\n",
              "`,`\n",
              "<img src=\"https://raw.githubusercontent.com/fbeilstein/neural_networks/master/lecture_3_nn_architectures/GAN3.webp\" width=750>\n",
              "`])\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for details see \"*Generative Adversarial Nets*\" by Ian J. Goodfellow et all.\n",
        "\n",
        "\n",
        "**for** number of training iterations **do**\n",
        "\n",
        "$~~~~$**for** $k$ steps **do**\n",
        "\n",
        "$~~~~$$~~~~$• Sample minibatch of $m$ noise samples $\\{z^{(1)},\\dots,z^{(m)}\\}$ from noise prior $p_g(z)$.\n",
        "\n",
        "$~~~~$$~~~~$• Sample minibatch of $m$ examples $\\{x^{(1)},\\dots,x^{(m)}\\}$ from data generating distribution $p_\\text{data}(x)$.\n",
        "\n",
        "$~~~~$$~~~~$• Update the discriminator by ascending its stochastic gradient:\n",
        "$$\n",
        "\\nabla_{\\theta_d} \\frac{1}{m} \\sum_{i=1}^m \\left[ \\ln D (x^{(i)}) + \\ln \\left( 1 - D(G(z^{(i)})) \\right)\\right]\n",
        "$$\n",
        "$~~~~$**end for**\n",
        "\n",
        "$~~~~$• Sample minibatch of $m$ noise samples $\\{z^{(1)},\\dots,z^{(m)}\\}$ from noise prior $p_g(z)$.\n",
        "\n",
        "$~~~~$• Update the generator by descending its stochastic gradient:\n",
        "$$\n",
        "\\nabla_{\\theta_g} \\frac{1}{m} \\sum_{i=1}^m \\ln \\left( 1 - D(G(z^{(i)})) \\right)\n",
        "$$\n",
        "\n",
        "**end for**"
      ],
      "metadata": {
        "id": "r8BjYgUw-oVh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$D$ - probability that data is genuine.\n",
        "\n",
        "For perfect discriminator $D(x) = 1$ and $D(G(z)) = 0$. In this case $\\ln D + \\ln(1-D(G)) = 0$ while for any other case $< 0$. **Discriminator maximizes loss**.\n",
        "\n",
        "$G$ - would be perfect if $D(G) = 1$, thus loss would be $-\\infty$. **Generator minimizes loss**\n",
        "\n",
        "$$\n",
        "\\min_G \\max_D \\frac{1}{m} \\sum_{i=1}^m \\left[ \\ln D (x^{(i)}) + \\ln \\left( 1 - D(G(z^{(i)})) \\right)\\right]\n",
        "$$\n",
        "\n",
        "![img](https://upload.wikimedia.org/wikipedia/commons/thumb/1/17/Inter-house_sports-_tug_of_war.jpg/640px-Inter-house_sports-_tug_of_war.jpg)\n",
        "\n",
        "It can be proven that balance is acieved when $D(x) = D(G(z)) = 1/2$, that basically means genuine and generated data are indistinguishable."
      ],
      "metadata": {
        "id": "uuNhexDoFKW9"
      }
    }
  ]
}